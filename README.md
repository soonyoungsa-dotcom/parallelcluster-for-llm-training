# AWS ParallelCluster for Distributed Training

![Architecture Diagram](img/architecture.png)

AWS ParallelClusterë¥¼ ì‚¬ìš©í•œ ë¶„ì‚° í•™ìŠµ í™˜ê²½ êµ¬ì¶•ì„ ìœ„í•œ ì—ì…‹ì…ë‹ˆë‹¤. GPU ë° CPU ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì»´í“¨íŠ¸ ë…¸ë“œë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, ëª¨ë‹ˆí„°ë§ ìŠ¤íƒê³¼ ìë™í™”ëœ ì„¤ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.

## ğŸ—ï¸ Architecture Overview

### ë…¸ë“œ ì—­í• 

- **LoginNode Pool (Optional)**: 
  - ì‚¬ìš©ì SSH ì ‘ê·¼ ë° ì‘ì—… ì œì¶œ ì „ìš©
  - ë°ì´í„° ì „ì²˜ë¦¬ ë° ê°„ë‹¨í•œ ì‘ì—… ìˆ˜í–‰
  - HeadNodeì˜ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ë³´í˜¸
  - Public Subnet (íŠ¹ì • IPë§Œ SSH í—ˆìš©)
  
- **HeadNode**: 
  - Slurm ìŠ¤ì¼€ì¤„ëŸ¬ ë° ì‘ì—… ê´€ë¦¬
  - NFS ì„œë²„ ì—­í•  (/home ê³µìœ )
  - Private Subnetì— ìœ„ì¹˜ (ë³´ì•ˆ)
  
- **ComputeNodes**: 
  - GPU ì›Œí¬ë¡œë“œ ì‹¤í–‰ ì „ìš©
  - Private Subnetì— ìœ„ì¹˜
  - Auto-scaling ì§€ì› (Slurm ì—°ë™)
  - EFA ë„¤íŠ¸ì›Œí¬ë¡œ ë…¸ë“œ ê°„ ê³ ì† í†µì‹ 

### ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

**AWS Managed Services (ê¶Œì¥)**:
- **Amazon Managed Prometheus (AMP)**: ë©”íŠ¸ë¦­ ì €ì¥ ë° ì¿¼ë¦¬
- **Amazon Managed Grafana (AMG)**: ëŒ€ì‹œë³´ë“œ ë° ì‹œê°í™”
- **ì¥ì **: ê´€ë¦¬ ë¶€ë‹´ ì—†ìŒ, ê³ ê°€ìš©ì„±, ìë™ ìŠ¤ì¼€ì¼ë§, AWS SSO í†µí•©

**Self-hosting (ëŒ€ì•ˆ)**:
- Standalone Monitoring Instance (t3.medium)
- Prometheus + Grafana ì§ì ‘ ìš´ì˜
- ALBë¥¼ í†µí•œ HTTPS ì ‘ê·¼
- í´ëŸ¬ìŠ¤í„°ì™€ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ README.md                                    # ì´ íŒŒì¼
â”œâ”€â”€ guide/                                       # ìƒì„¸ ê°€ì´ë“œ ë¬¸ì„œ
â”‚   â”œâ”€â”€ AMP-AMG-SETUP.md                         # AWS Managed Prometheus + Grafana ì„¤ì •
â”‚   â”œâ”€â”€ DCGM-TO-CLOUDWATCH.md                    # GPU ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
â”‚   â”œâ”€â”€ EFA-MONITORING.md                        # EFA ë„¤íŠ¸ì›Œí¬ ëª¨ë‹ˆí„°ë§
â”‚   â”œâ”€â”€ NVLINK-MONITORING.md                     # NVLink ëª¨ë‹ˆí„°ë§
â”‚   â”œâ”€â”€ PROMETHEUS-METRICS.md                    # Prometheus ë©”íŠ¸ë¦­ ê°€ì´ë“œ
â”‚   â”œâ”€â”€ QUICKSTART-EFA-MONITORING.md             # ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
â”‚   â”œâ”€â”€ CLUSTER-RECREATION-GUIDE.md              # í´ëŸ¬ìŠ¤í„° ì¬ìƒì„± ê°€ì´ë“œ
â”‚   â”œâ”€â”€ TIMEOUT-CONFIGURATION.md                 # íƒ€ì„ì•„ì›ƒ ì„¤ì • ê°€ì´ë“œ
â”‚   â””â”€â”€ README.md                                # ê°€ì´ë“œ ëª©ì°¨
â”‚
â”œâ”€â”€ parallelcluster-infrastructure.yaml          # CloudFormation ì¸í”„ë¼ í…œí”Œë¦¿
â”œâ”€â”€ cluster-config.yaml.template                 # í´ëŸ¬ìŠ¤í„° ì„¤ì • í…œí”Œë¦¿
â”œâ”€â”€ environment-variables.sh                     # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ environment-variables-bailey.sh              # í™˜ê²½ ë³€ìˆ˜ ì˜ˆì œ (bailey)
â”‚
â”œâ”€â”€ config/                                      # ë…¸ë“œ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ (S3 ì—…ë¡œë“œìš©)
â”‚   â”œâ”€â”€ README.md                                # config ë””ë ‰í† ë¦¬ ì„¤ëª…
â”‚   â”œâ”€â”€ STRUCTURE-SUMMARY.md                     # êµ¬ì¡° ìš”ì•½
â”‚   â”œâ”€â”€ monitoring/                              # ëª¨ë‹ˆí„°ë§ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ README.md                            # UserData ìë™ ì„¤ì¹˜ ë°©ì‹ ì„¤ëª…
â”‚   â”‚   â””â”€â”€ setup-monitoring-instance.sh         # ìˆ˜ë™ ì¬ì„¤ì¹˜ìš© (ì°¸ê³ )
â”‚   â”œâ”€â”€ headnode/                                # HeadNode ì„¤ì •
â”‚   â”‚   â””â”€â”€ setup-headnode.sh                    # Prometheus + CloudWatch
â”‚   â”œâ”€â”€ loginnode/                               # LoginNode ì„¤ì •
â”‚   â”‚   â””â”€â”€ setup-loginnode.sh                   # ê¸°ë³¸ ë„êµ¬ + CloudWatch
â”‚   â”œâ”€â”€ compute/                                 # ComputeNode ì„¤ì •
â”‚   â”‚   â””â”€â”€ setup-compute-node.sh                # GPU/CPU ëª¨ë“œë³„ ì„¤ì¹˜
â”‚   â”œâ”€â”€ cloudwatch/                              # CloudWatch ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ dcgm-to-cloudwatch.sh                # DCGM ë©”íŠ¸ë¦­ ì „ì†¡
â”‚   â”‚   â””â”€â”€ create-efa-dashboard.sh              # EFA ëŒ€ì‹œë³´ë“œ ìƒì„±
â”‚   â”œâ”€â”€ nccl/                                    # NCCL ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ efa/                                     # EFA ë“œë¼ì´ë²„ ì„¤ì¹˜
â”‚
â”œâ”€â”€ scripts/                                     # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ check-compute-setup.sh                   # ComputeNode ì„¤ì • í™•ì¸
â”‚   â”œâ”€â”€ monitor-compute-node-setup.sh            # ì„¤ì¹˜ ì§„í–‰ ëª¨ë‹ˆí„°ë§
â”‚   â””â”€â”€ upload-monitoring-scripts.sh             # S3 ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
â”‚
â””â”€â”€ security-best-practices/                     # ë³´ì•ˆ ê°€ì´ë“œ
    â””â”€â”€ SECURITY.md                              # ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€
```

## ğŸ“¦ Prerequisites

```bash
# AWS CLI v2
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip && sudo ./aws/install

# AWS ParallelCluster CLI v3.14.0 in virtual environment
python3 -m venv pcluster-venv
source pcluster-venv/bin/activate
pip install --upgrade "aws-parallelcluster==3.14.0"

# envsubst (í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜)
# MacOS
curl -L https://github.com/a8m/envsubst/releases/download/v1.2.0/envsubst-`uname -s`-`uname -m` -o envsubst
chmod +x envsubst && sudo mv envsubst /usr/local/bin

# Linux (CloudShellì—ëŠ” ê¸°ë³¸ ì„¤ì¹˜ë¨)
sudo yum install -y gettext  # Amazon Linux
# sudo apt-get install -y gettext-base  # Ubuntu

# AWS ìê²© ì¦ëª… ì„¤ì •
# regionì€ í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•  ë¦¬ì „ê³¼ ì¼ì¹˜í•´ì•¼í•¨, cluster-config.yaml íŒŒì¼ì—ì„œ ì°¸ì¡°í•¨
aws configure
```

## ğŸš€ Quick Start

### 1. ì¸í”„ë¼ ë°°í¬

**ëª¨ë‹ˆí„°ë§ ì˜µì…˜**:
- `none`: ëª¨ë‹ˆí„°ë§ ì—†ìŒ (ìµœì†Œ êµ¬ì„±)
- `self-hosting`: Standalone Prometheus + Grafana (t3.medium ì¸ìŠ¤í„´ìŠ¤)
- `amp-only`: AWS Managed Prometheusë§Œ ì‚¬ìš©
- `amp+amg`: AWS Managed Prometheus + Grafana (ê¶Œì¥)

```bash
# í˜„ì¬ IP í™•ì¸
MY_IP=$(curl -s https://checkip.amazonaws.com)
echo "Your IP: $MY_IP"

# [none] ê¸°ë³¸ ë°°í¬ (ìµœì†Œ ì„¤ì •)
REGION="us-east-2"
aws cloudformation create-stack \
  --stack-name parallelcluster-infra \
  --region $REGION \
  --template-body file://parallelcluster-infrastructure.yaml \
  --parameters \
    ParameterKey=PrimarySubnetAZ,ParameterValue=${REGION}a \
    ParameterKey=MonitoringType,ParameterValue=none \
  --capabilities CAPABILITY_IAM

# [self-hosting] Self-hosted monitoring (EC2+ALB)
aws cloudformation create-stack \
  --stack-name parallelcluster-infra \
  --region $REGION \
  --template-body file://parallelcluster-infrastructure.yaml \
  --parameters \
    ParameterKey=PrimarySubnetAZ,ParameterValue=${REGION}a \
    ParameterKey=MonitoringType,ParameterValue=self-hosting \
    ParameterKey=SecondarySubnetAZ,ParameterValue=${REGION}b \
    ParameterKey=S3BucketName,ParameterValue=my-pcluster-scripts \
    ParameterKey=MonitoringKeyPair,ParameterValue=your-key \
    ParameterKey=AllowedIPsForMonitoringSSH,ParameterValue="${MY_IP}/32" \
    ParameterKey=AllowedIPsForALB,ParameterValue="${MY_IP}/32" \
  --capabilities CAPABILITY_IAM

# [amp-only] AWS Managed Prometheus (AMP) ì‚¬ìš© (ìë™ ìƒì„±)
aws cloudformation create-stack \
  --stack-name parallelcluster-infra \
  --region $REGION \
  --template-body file://parallelcluster-infrastructure.yaml \
  --parameters \
    ParameterKey=PrimarySubnetAZ,ParameterValue=${REGION}a \
    ParameterKey=MonitoringType,ParameterValue=amp-only \
  --capabilities CAPABILITY_IAM

## AMP Workspace ì •ë³´ í™•ì¸
AMP_WORKSPACE_ID=$(aws cloudformation describe-stacks \
  --stack-name parallelcluster-infra \
  --query 'Stacks[0].Outputs[?OutputKey==`AMPWorkspaceId`].OutputValue' \
  --output text)

AMP_ENDPOINT=$(aws cloudformation describe-stacks \
  --stack-name parallelcluster-infra \
  --query 'Stacks[0].Outputs[?OutputKey==`AMPPrometheusEndpoint`].OutputValue' \
  --output text)

echo "AMP Workspace ID: $AMP_WORKSPACE_ID"
echo "AMP Endpoint: $AMP_ENDPOINT"

# âš ï¸ ì°¸ê³ : AMP Endpointë¥¼ ë¸Œë¼ìš°ì €ë¡œ ì ‘ê·¼í•˜ë©´ <HttpNotFoundException/>ê°€ í‘œì‹œë©ë‹ˆë‹¤.
# ì´ëŠ” ì •ìƒ ë™ì‘ì…ë‹ˆë‹¤! AMPëŠ” Prometheus remote_write APIë§Œ ì œê³µí•˜ë©°,
# ë©”íŠ¸ë¦­ ì¡°íšŒëŠ” Grafanaë¥¼ í†µí•´ì„œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## AMP Workspace ìƒíƒœ í™•ì¸ (ACTIVEì—¬ì•¼ ì •ìƒ)
aws amp describe-workspace --workspace-id $AMP_WORKSPACE_ID \
  --query 'workspace.status.statusCode' --output text

# [amp+amg] ì™„ì „ ê´€ë¦¬í˜• ëª¨ë‹ˆí„°ë§ ë°°í¬ (AMP + AMG, ê¶Œì¥)
aws cloudformation create-stack \
  --stack-name parallelcluster-infra \
  --region $REGION \
  --template-body file://parallelcluster-infrastructure.yaml \
  --parameters \
    ParameterKey=PrimarySubnetAZ,ParameterValue=${REGION}a \
    ParameterKey=MonitoringType,ParameterValue=amp+amg \
  --capabilities CAPABILITY_NAMED_IAM

# ë°°í¬ ì™„ë£Œ ëŒ€ê¸° (~5-8ë¶„)
aws cloudformation wait stack-create-complete \
  --stack-name parallelcluster-infra \
  --region $REGION
```

### 2. S3 ë²„í‚· ë° config ì—…ë¡œë“œ

```bash
# S3 ë²„í‚· ìƒì„±
aws s3 mb s3://my-pcluster-scripts --region us-east-2

# config ë””ë ‰í† ë¦¬ ì—…ë¡œë“œ (ë…¸ë“œ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸)
# âš ï¸ ì¤‘ìš”: CustomActionsê°€ ì´ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ì°¸ì¡°í•©ë‹ˆë‹¤
aws s3 sync config/ s3://my-pcluster-scripts/config/ --region us-east-2

# ì—…ë¡œë“œ í™•ì¸
aws s3 ls s3://my-pcluster-scripts/config/ --recursive

# ì˜ˆìƒ ì¶œë ¥:
# config/headnode/setup-headnode.sh
# config/loginnode/setup-loginnode.sh
# config/compute/setup-compute-node.sh
# config/cloudwatch/dcgm-to-cloudwatch.sh
# config/cloudwatch/create-efa-dashboard.sh
# ... (ê¸°íƒ€ íŒŒì¼ë“¤)
```

**config ë””ë ‰í† ë¦¬ êµ¬ì¡°**:
- `headnode/`: HeadNode ì„¤ì • (Prometheus + CloudWatch)
- `loginnode/`: LoginNode ì„¤ì • (ê¸°ë³¸ ë„êµ¬ + CloudWatch)
- `compute/`: ComputeNode ì„¤ì • (GPU/CPU ëª¨ë“œë³„ ì„¤ì¹˜)
- `cloudwatch/`: CloudWatch ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸
- `nccl/`: NCCL ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
- `efa/`: EFA ë“œë¼ì´ë²„ ì„¤ì¹˜

ğŸ“– **ìƒì„¸ êµ¬ì¡°**: [config/README.md](config/README.md)

### 3. í´ëŸ¬ìŠ¤í„° ì„¤ì • ìƒì„±

```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
vim environment-variables.sh
# í•„ìˆ˜ ìˆ˜ì • í•­ëª©:
# - STACK_NAME
# - KEY_PAIR_NAME
# _ CLUSTER_NAME
# - S3_BUCKET

# ì»¤ìŠ¤í…€ í•­ëª©
# HeadNode Configuration
# LoginNode Configuration
# Compute Queue Configuration
# ComputeResource Configuration
# CustomActions Enable/Disable


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ì„¤ì • ìƒì„±
source environment-variables.sh
envsubst < cluster-config.yaml.template > cluster-config.yaml
```

### 4. í´ëŸ¬ìŠ¤í„° ìƒì„±

```bash
# í´ëŸ¬ìŠ¤í„° ìƒì„± (my-clusterëŠ” CLUSTER_NAMEê³¼ ë™ì¼í•´ì•¼í•¨)
pcluster create-cluster \
  --cluster-name my-cluster \
  --cluster-configuration cluster-config.yaml

# ìƒì„± ìƒíƒœ í™•ì¸
pcluster describe-cluster --cluster-name my-cluster
```

**í´ëŸ¬ìŠ¤í„° ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí•œ ê²½ìš°**:
- ğŸ“– **í´ëŸ¬ìŠ¤í„° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ë¡œê·¸ í™•ì¸**: [ì•„ë˜ ëª¨ë‹ˆí„°ë§ ì„¹ì…˜ ì°¸ì¡°](#í´ëŸ¬ìŠ¤í„°-ìƒíƒœ-ëª¨ë‹ˆí„°ë§)
- ğŸ“– **ë¡œê·¸ ë‚´ë³´ë‚´ê¸° ìƒì„¸ ê°€ì´ë“œ**: [AWS ParallelCluster ë¡œê·¸ ë‚´ë³´ë‚´ê¸°](https://docs.aws.amazon.com/ko_kr/parallelcluster/latest/ug/pcluster.export-cluster-logs-v3.html)

### 5. ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜

ì„¸ ê°€ì§€ ë°©ë²• ì¤‘ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”:

**ë°©ë²• ì„ íƒ ê°€ì´ë“œ**:

| ë°©ë²• | ì„¤ì¹˜ ì‹œì  | ì„¤ì¹˜ ì‹œê°„ | íƒ€ì„ì•„ì›ƒ ìœ„í—˜ | ê¶Œì¥ ìš©ë„ |
|------|-----------|-----------|---------------|-----------|
| **1. CustomActions** | í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œ | 15-20ë¶„ | ì¤‘ê°„ | ê¸°ë³¸ GPU/CPU í™˜ê²½ |
| **2. FSx ê³µìœ ** | í´ëŸ¬ìŠ¤í„° ìƒì„± í›„ | 10-15ë¶„ (1íšŒ) | ì—†ìŒ | NCCL ë“± ëŒ€ìš©ëŸ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| **3. ì»¨í…Œì´ë„ˆ** | ì‹¤í–‰ ì‹œ | ì¦‰ì‹œ | ì—†ìŒ | ì™„ì „í•œ ì¬í˜„ì„± í•„ìš” ì‹œ |

**ì¡°í•© ì¶”ì²œ**:
- ë°©ë²• 1 (ê¸°ë³¸ í™˜ê²½) + ë°©ë²• 2 (NCCL) + ë°©ë²• 3 (ì›Œí¬ë¡œë“œ)
- ë˜ëŠ” ë°©ë²• 3ë§Œ ì‚¬ìš© (ê°€ì¥ ê°„ë‹¨)

#### ë°©ë²• 1: CustomActions ìë™ ì„¤ì¹˜ (Timeout ë°©ì§€ë¥¼ ìœ„í•´ ê²½ëŸ‰í™” ì¶”ì²œ)

í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œ `environment-variables.sh`ì—ì„œ ì„¤ì •:

```bash
# environment-variables.sh ì„¤ì •
export COMPUTE_SETUP_TYPE="gpu"  # GPU ì¸ìŠ¤í„´ìŠ¤ìš©
# ë˜ëŠ”
export COMPUTE_SETUP_TYPE="cpu"  # CPU ì¸ìŠ¤í„´ìŠ¤ìš©
```

**GPU ëª¨ë“œ (`COMPUTE_SETUP_TYPE="gpu"`)** - GPU ì¸ìŠ¤í„´ìŠ¤ìš© (p5, p4d, g5, g4dn):
- Docker + Pyxis (ì»¨í…Œì´ë„ˆ ì‹¤í–‰)
- EFA Installer (ê³ ì† ë„¤íŠ¸ì›Œí‚¹)
- DCGM Exporter (GPU ë©”íŠ¸ë¦­)
- Node Exporter (ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­)
- CloudWatch Agent
- ì„¤ì¹˜ ì‹œê°„: ~15-20ë¶„

**CPU ëª¨ë“œ (`COMPUTE_SETUP_TYPE="cpu"`)** - CPU ì¸ìŠ¤í„´ìŠ¤ìš© (c5, m5, r5):
- Docker + Pyxis (ì»¨í…Œì´ë„ˆ ì‹¤í–‰)
- CloudWatch Agent
- ì„¤ì¹˜ ì‹œê°„: ~5-10ë¶„

**ë¹„í™œì„±í™” (`COMPUTE_SETUP_TYPE=""`)** - ìµœì†Œ ì„¤ì •:
- CustomActions ìˆ˜í–‰ í•˜ì§€ ì•ŠìŒ
- ì„¤ì¹˜ ì‹œê°„: ~2-3ë¶„

#### ë°©ë²• 2: FSx ê³µìœ  ìŠ¤í† ë¦¬ì§€ í™œìš© (NCCL ì„¤ì¹˜ ê¶Œì¥)

FSx Lustreì— í•œ ë²ˆë§Œ ì„¤ì¹˜í•˜ê³  ëª¨ë“  ComputeNodeì—ì„œ ì°¸ì¡°:

```bash
# 1. HeadNodeì— SSH ì ‘ì†
ssh -i your-key.pem ubuntu@<headnode-ip>

# 2. NCCL ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ (config/nccl/ ë””ë ‰í† ë¦¬ì— ìˆìŒ)
# ë˜ëŠ” S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
aws s3 cp s3://my-pcluster-scripts/config/nccl/install-nccl-shared.sh /fsx/nccl/
chmod +x /fsx/nccl/install-nccl-shared.sh

# 3. FSxì— NCCL ì„¤ì¹˜ (í•œ ë²ˆë§Œ, 10-15ë¶„ ì†Œìš”)
sudo bash /fsx/nccl/install-nccl-shared.sh v2.28.7-1 v1.17.2-aws /fsx

# ì„¤ì¹˜ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼:
# /fsx/nccl/setup-nccl-env.sh  â† ëª¨ë“  ë…¸ë“œì—ì„œ sourceí•˜ì—¬ ì‚¬ìš©
```

**ComputeNode ìë™ ê°ì§€**:
- âœ… ìë™ìœ¼ë¡œ `/fsx/nccl/setup-nccl-env.sh` ê°ì§€ ë° ì„¤ì •
- âš ï¸ **ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œ**: ìˆ˜ë™ ì ìš© í•„ìš”

```bash
# ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ComputeNodeì— ì ìš© (í´ëŸ¬ìŠ¤í„° ìƒì„± í›„ NCCL ì„¤ì¹˜í•œ ê²½ìš°)
bash /fsx/nccl/apply-nccl-to-running-nodes.sh

# ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ ëª¨ë“  ë…¸ë“œì— ì ìš©
srun --nodes=ALL bash -c 'cat > /etc/profile.d/nccl-shared.sh << "EOF"
source /fsx/nccl/setup-nccl-env.sh
EOF
chmod +x /etc/profile.d/nccl-shared.sh'

# ì ìš© í™•ì¸
srun --nodes=ALL bash -c 'source /etc/profile.d/nccl-shared.sh && echo "NCCL: $LD_LIBRARY_PATH"'
```

**ê¶Œì¥ ì›Œí¬í”Œë¡œìš°**:
1. í´ëŸ¬ìŠ¤í„° ìƒì„± (ComputeNode MinCount=0ìœ¼ë¡œ ì„¤ì •)
2. HeadNodeì—ì„œ NCCLì„ FSxì— ì„¤ì¹˜
3. Slurm job ì œì¶œ â†’ ComputeNode ìë™ ì‹œì‘ â†’ NCCL ìë™ ê°ì§€ âœ…

**ì¥ì **: 
- ë¹ ë¥¸ ì„¤ì¹˜ (10-15ë¶„, í•œ ë²ˆë§Œ)
- ìŠ¤í† ë¦¬ì§€ íš¨ìœ¨ (ëª¨ë“  ë…¸ë“œê°€ ê³µìœ )
- ë²„ì „ ì¼ê´€ì„± ë³´ì¥
- ìƒˆ ë…¸ë“œ ìë™ ê°ì§€
- CustomActions íƒ€ì„ì•„ì›ƒ íšŒí”¼

**NCCL ë²„ì „ í™•ì¸**:
```bash
# ì„¤ì¹˜ëœ NCCL ë²„ì „ í™•ì¸
ls -la /fsx/nccl/
cat /fsx/nccl/setup-nccl-env.sh
```

ğŸ“– **ìƒì„¸ NCCL ì„¤ì¹˜ ê°€ì´ë“œ**: [config/nccl/README.md](config/nccl/README.md)  
ğŸ“– **NCCL ì»¨í…Œì´ë„ˆ ì‚¬ìš©**: [config/nccl/README-CONTAINER.md](config/nccl/README-CONTAINER.md)  
ğŸ“– **NCCL ì„¤ì¹˜ íƒ€ì´ë°**: [guide/NCCL-INSTALLATION-TIMING.md](guide/NCCL-INSTALLATION-TIMING.md)

#### ë°©ë²• 3: ì»¨í…Œì´ë„ˆ ì‚¬ìš©

ì‚¬ì „ êµ¬ì„±ëœ ì»¨í…Œì´ë„ˆë¡œ ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ ë¶ˆí•„ìš”:

```bash
# Slurm jobì—ì„œ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
srun --container-image=nvcr.io/nvidia/pytorch:24.01-py3 \
     --container-mounts=/fsx:/fsx \
     python /fsx/train.py
```

**ì¥ì **: ì„¤ì¹˜ ë¶ˆí•„ìš”, ì¬í˜„ ê°€ëŠ¥, ë²„ì „ ê´€ë¦¬ ìš©ì´

### Bootstrap íƒ€ì„ì•„ì›ƒ ì„¤ì •

ParallelClusterëŠ” ë…¸ë“œ ì´ˆê¸°í™” ì‹œ CloudFormation WaitConditionì„ ì‚¬ìš©í•˜ë©°, ê¸°ë³¸ íƒ€ì„ì•„ì›ƒì€ 30ë¶„ì…ë‹ˆë‹¤. GPU ì¸ìŠ¤í„´ìŠ¤(íŠ¹íˆ p5en.48xlarge)ëŠ” EFA ë“œë¼ì´ë²„ì™€ NVIDIA ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ì— ì‹œê°„ì´ ë” ê±¸ë¦¬ë¯€ë¡œ ì‚¬ì „ í…ŒìŠ¤íŠ¸ í›„ íƒ€ì„ì•„ì›ƒì„ ëŠ˜ë¦¬ì‹œê¸¸ ë°”ëë‹ˆë‹¤.

**í˜„ì¬ ì„¤ì •** (`cluster-config.yaml`):

```yaml
DevSettings:
  Timeouts:
    HeadNodeBootstrapTimeout: 3600      # 60ë¶„
    ComputeNodeBootstrapTimeout: 2400   # 40ë¶„
```

**íƒ€ì„ì•„ì›ƒ ê·¼ê±°**:

| ë…¸ë“œ íƒ€ì… | ì‹¤ì œ ì„¤ì¹˜ ì‹œê°„ | íƒ€ì„ì•„ì›ƒ ì„¤ì • | ì•ˆì „ ë§ˆì§„ |
|-----------|----------------|---------------|-----------|
| **HeadNode** | ~5ë¶„ | 60ë¶„ | 12Ã— |
| **ComputeNode** | 15-20ë¶„ | 40ë¶„ | 2Ã— |

**ComputeNode ì„¤ì¹˜ ì‹œê°„ ìƒì„¸**:

```
EFA Driver:              5-10ë¶„  â† ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¼
Docker + NVIDIA Toolkit:  3ë¶„
Pyxis:                    2ë¶„
CloudWatch Agent:         1ë¶„
DCGM Exporter:            1ë¶„
Node Exporter:            1ë¶„
NCCL ì„¤ì •:                5ì´ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ì‹¤ì œ ì‹œê°„:            15-20ë¶„
íƒ€ì„ì•„ì›ƒ ì„¤ì •:            40ë¶„
ì•ˆì „ ë§ˆì§„:               20ë¶„
```

**íƒ€ì„ì•„ì›ƒ ì¦ìƒ**:
- ComputeNodeê°€ `running` ìƒíƒœì—ì„œ ê³§ë°”ë¡œ `shutting-down`ìœ¼ë¡œ ì „í™˜
- CloudWatch ë¡œê·¸ì—ì„œ ì„¤ì¹˜ê°€ ì¤‘ê°„ì— ì¤‘ë‹¨ë¨
- CloudFormation ì´ë²¤íŠ¸ì— "timeout" ë©”ì‹œì§€

**íƒ€ì„ì•„ì›ƒ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš°**:
- âœ… ëŠë¦° ë„¤íŠ¸ì›Œí¬ í™˜ê²½
- âœ… ëŒ€í˜• ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… (ë” ë§ì€ ë“œë¼ì´ë²„ ì„¤ì¹˜)
- âœ… ë³µì¡í•œ CustomActions ìŠ¤í¬ë¦½íŠ¸
- âœ… ì¶”ê°€ ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜

**íƒ€ì„ì•„ì›ƒ ëª¨ë‹ˆí„°ë§**:

```bash
# CloudFormation ì´ë²¤íŠ¸ í™•ì¸
aws cloudformation describe-stack-events \
  --stack-name p5en-48xlarge-cluster \
  --region us-east-2 \
  --query 'StackEvents[?contains(ResourceStatusReason, `timeout`)]'

# ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœ í™•ì¸
aws ec2 describe-instances \
  --filters "Name=tag:aws:cloudformation:stack-name,Values=p5en-48xlarge-cluster" \
  --region us-east-2 \
  --query 'Reservations[*].Instances[*].{ID:InstanceId,State:State.Name,LaunchTime:LaunchTime}'

# CloudWatch ë¡œê·¸ í™•ì¸
aws logs tail /aws/parallelcluster/p5en-48xlarge-cluster --region us-east-2 --since 1h
```

ğŸ“– **íƒ€ì„ì•„ì›ƒ ìƒì„¸ ê°€ì´ë“œ**: [guide/TIMEOUT-CONFIGURATION.md](guide/TIMEOUT-CONFIGURATION.md)

### 6. ëª¨ë‹ˆí„°ë§ ì ‘ê·¼

#### Option 1: Amazon Managed Grafana (ê¶Œì¥)

```bash
# Grafana ì ‘ì† ì •ë³´ í™•ì¸ (amp+amg ì˜µì…˜ ì‚¬ìš© ì‹œ)
aws cloudformation describe-stacks \
  --stack-name parallelcluster-infra \
  --query 'Stacks[0].Outputs[?OutputKey==`GrafanaAccessInstructions`].OutputValue' \
  --output text

# ë˜ëŠ” URLë§Œ í™•ì¸
GRAFANA_URL=$(aws cloudformation describe-stacks \
  --stack-name parallelcluster-infra \
  --query 'Stacks[0].Outputs[?OutputKey==`ManagedGrafanaWorkspaceEndpoint`].OutputValue' \
  --output text)

echo "Grafana: https://${GRAFANA_URL}"
# AWS SSOë¡œ ë¡œê·¸ì¸ (ê¶Œí•œ ë¶€ì—¬ í›„)
```

#### Option 2: Self-hosting (ALB)

```bash
# ALB DNS í™•ì¸
aws cloudformation describe-stacks \
  --stack-name parallelcluster-infra \
  --query 'Stacks[0].Outputs[?OutputKey==`ALBDNSName`].OutputValue' \
  --output text

# ì ‘ì†: https://<ALB-DNS>/grafana/
# ê¸°ë³¸ ë¡œê·¸ì¸: admin / Grafana4PC!
```

### 7. NCCL ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# NCCL í…ŒìŠ¤íŠ¸ ì„¤ì¹˜ (FSx ê³µìœ  ìŠ¤í† ë¦¬ì§€ì—)
bash /fsx/nccl/install-nccl-tests.sh

# ë‹¨ê³„ë³„ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
# Phase 1: ë‹¨ì¼ ë…¸ë“œ ê¸°ë³¸ ì„±ëŠ¥
sbatch /fsx/nccl/phase1-baseline.sbatch

# Phase 2: ë©€í‹° ë…¸ë“œ í™•ì¥ì„±
sbatch /fsx/nccl/phase2-multinode.sbatch

# Phase 3: ì‹¤ì œ ì›Œí¬ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜
sbatch /fsx/nccl/phase3-workload.sbatch

# Phase 4: ìµœì í™”ëœ ì„¤ì •
sbatch /fsx/nccl/phase4-optimization.sbatch

# ì‘ì—… ìƒíƒœ í™•ì¸
squeue

# ê²°ê³¼ í™•ì¸
ls -lh /fsx/nccl-tests/results/
```

**ì»¨í…Œì´ë„ˆ ê¸°ë°˜ í…ŒìŠ¤íŠ¸**:
```bash
# NVIDIA PyTorch ì»¨í…Œì´ë„ˆë¡œ í…ŒìŠ¤íŠ¸
sbatch /fsx/nccl/phase1-baseline-container.sbatch
sbatch /fsx/nccl/phase3-workload-container.sbatch
sbatch /fsx/nccl/phase4-optimization-container.sbatch
```

ğŸ“– **NCCL ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ì „ ê°€ì´ë“œ**: [guide/NCCL-PERFORMANCE-TESTING.md](guide/NCCL-PERFORMANCE-TESTING.md)  
ğŸ“– **NCCL ì„¤ì¹˜ ê°€ì´ë“œ**: [config/nccl/README.md](config/nccl/README.md)

## ğŸ“¡ Monitoring

### í´ëŸ¬ìŠ¤í„° ìƒíƒœ ëª¨ë‹ˆí„°ë§

í´ëŸ¬ìŠ¤í„° ìƒì„± ë° ìš´ì˜ ì¤‘ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

#### ê¸°ë³¸ ìƒíƒœ í™•ì¸

```bash
# í´ëŸ¬ìŠ¤í„° ì „ì²´ ìƒíƒœ
pcluster describe-cluster --cluster-name my-cluster

# ì£¼ìš” ìƒíƒœ ê°’:
# - CREATE_IN_PROGRESS: ìƒì„± ì¤‘
# - CREATE_COMPLETE: ìƒì„± ì™„ë£Œ
# - CREATE_FAILED: ìƒì„± ì‹¤íŒ¨
# - UPDATE_IN_PROGRESS: ì—…ë°ì´íŠ¸ ì¤‘
# - UPDATE_COMPLETE: ì—…ë°ì´íŠ¸ ì™„ë£Œ
```

#### ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

```bash
# CloudWatch ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ í™•ì¸ (ì‹¤ì‹œê°„)
pcluster get-cluster-log-events \
  --cluster-name my-cluster \
  --log-stream-name cfn-init

# ìµœê·¼ 1ì‹œê°„ ë¡œê·¸
pcluster get-cluster-log-events \
  --cluster-name my-cluster \
  --log-stream-name cfn-init \
  --start-time $(date -u -d '1 hour ago' '+%Y-%m-%dT%H:%M:%S.000Z')

# íŠ¹ì • ë…¸ë“œ ë¡œê·¸ í™•ì¸
pcluster get-cluster-log-events \
  --cluster-name my-cluster \
  --log-stream-name ip-10-0-16-123.cfn-init  # ë…¸ë“œ IP ê¸°ë°˜
```

#### ë¡œê·¸ ì „ì²´ ë‚´ë³´ë‚´ê¸°

ë¬¸ì œ í•´ê²° ì‹œ ìœ ìš©í•œ ì „ì²´ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ:

```bash
# ëª¨ë“  ë¡œê·¸ë¥¼ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ
pcluster export-cluster-logs \
  --cluster-name my-cluster \
  --output-file my-cluster-logs.tar.gz

# ì••ì¶• í•´ì œ ë° í™•ì¸
tar -xzf my-cluster-logs.tar.gz
ls -la my-cluster-logs/

# ë¡œê·¸ êµ¬ì¡°:
# my-cluster-logs/
# â”œâ”€â”€ cfn-init.log           # CloudFormation ì´ˆê¸°í™”
# â”œâ”€â”€ cloud-init.log         # ì¸ìŠ¤í„´ìŠ¤ ë¶€íŒ…
# â”œâ”€â”€ clustermgtd.log        # í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ë°ëª¬
# â”œâ”€â”€ slurm_resume.log       # Slurm ë…¸ë“œ ì‹œì‘
# â”œâ”€â”€ slurm_suspend.log      # Slurm ë…¸ë“œ ì¤‘ì§€
# â””â”€â”€ compute/               # ComputeNode ë¡œê·¸
#     â””â”€â”€ ip-10-0-16-*.log
```

**íŠ¹ì • ê¸°ê°„ ë¡œê·¸ ë‚´ë³´ë‚´ê¸°**:
```bash
# ìµœê·¼ 1ì‹œê°„ ë¡œê·¸ë§Œ
pcluster export-cluster-logs \
  --cluster-name my-cluster \
  --output-file recent-logs.tar.gz \
  --start-time $(date -u -d '1 hour ago' '+%Y-%m-%dT%H:%M:%S.000Z')

# íŠ¹ì • ê¸°ê°„ ë¡œê·¸
pcluster export-cluster-logs \
  --cluster-name my-cluster \
  --output-file period-logs.tar.gz \
  --start-time 2024-01-15T10:00:00.000Z \
  --end-time 2024-01-15T12:00:00.000Z
```

#### ë¡œê·¸ í•„í„°ë§ ë° ë¶„ì„

```bash
# ì—ëŸ¬ ë©”ì‹œì§€ ê²€ìƒ‰
pcluster get-cluster-log-events \
  --cluster-name my-cluster \
  --log-stream-name cfn-init \
  --query 'events[?contains(message, `ERROR`)]'

# íŠ¹ì • í‚¤ì›Œë“œ ê²€ìƒ‰ (ì˜ˆ: NCCL)
pcluster get-cluster-log-events \
  --cluster-name my-cluster \
  --log-stream-name cfn-init | grep -i nccl

# íƒ€ì„ì•„ì›ƒ ê´€ë ¨ ë¡œê·¸ í™•ì¸
tar -xzf my-cluster-logs.tar.gz
grep -r "timeout\|timed out" my-cluster-logs/
```

#### ë¬¸ì œ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# 1. í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
pcluster describe-cluster --cluster-name my-cluster

# 2. CloudFormation ìŠ¤íƒ ì´ë²¤íŠ¸ í™•ì¸
aws cloudformation describe-stack-events \
  --stack-name my-cluster \
  --query 'StackEvents[?ResourceStatus==`CREATE_FAILED`]'

# 3. ë¡œê·¸ ë‚´ë³´ë‚´ê¸° ë° ë¶„ì„
pcluster export-cluster-logs \
  --cluster-name my-cluster \
  --output-file debug-logs.tar.gz

# 4. ì—ëŸ¬ ë©”ì‹œì§€ ê²€ìƒ‰
tar -xzf debug-logs.tar.gz
grep -r "ERROR\|FAILED\|timeout" debug-logs/
```

#### ì¼ë°˜ì ì¸ ìƒì„± ì‹¤íŒ¨ ì›ì¸

| ì¦ìƒ | ì›ì¸ | í•´ê²° ë°©ë²• |
|------|------|-----------|
| `CREATE_FAILED` | CustomActions íƒ€ì„ì•„ì›ƒ | `COMPUTE_SETUP_TYPE=""` ì„¤ì • í›„ ì¬ìƒì„± |
| `CREATE_FAILED` | ìš©ëŸ‰ ë¶€ì¡± | ë‹¤ë¥¸ AZ ì‹œë„ ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ë³€ê²½ |
| `CREATE_FAILED` | IAM ê¶Œí•œ ë¶€ì¡± | CloudFormation ìŠ¤íƒ ì´ë²¤íŠ¸ í™•ì¸ |
| ComputeNode ì‹œì‘ ì•ˆë¨ | Slurm ì„¤ì • ì˜¤ë¥˜ | `sinfo`, `squeue` í™•ì¸ |
| ëŠë¦° ìƒì„± ì†ë„ | CustomActions ì‹¤í–‰ ì¤‘ | ì •ìƒ, ë¡œê·¸ë¡œ ì§„í–‰ ìƒí™© í™•ì¸ |

ğŸ“– **ë¡œê·¸ ë‚´ë³´ë‚´ê¸° ìƒì„¸ ê°€ì´ë“œ**: [AWS ParallelCluster ë¡œê·¸ ë‚´ë³´ë‚´ê¸°](https://docs.aws.amazon.com/ko_kr/parallelcluster/latest/ug/pcluster.export-cluster-logs-v3.html)

---

### í†µí•© ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ

ì´ ì•„í‚¤í…ì²˜ëŠ” GPU, ì‹œìŠ¤í…œ, ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ì„ í¬ê´„í•˜ëŠ” ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒì„ ì œê³µí•©ë‹ˆë‹¤:

| ëª¨ë‹ˆí„°ë§ ì˜ì—­ | ë„êµ¬ | ë©”íŠ¸ë¦­ | í¬íŠ¸ |
|--------------|------|--------|------|
| **GPU ì„±ëŠ¥** | DCGM Exporter | GPU ì‚¬ìš©ë¥ , ë©”ëª¨ë¦¬, ì˜¨ë„, ì „ë ¥ | 9400 |
| **NVLink** | DCGM | GPU ê°„ í†µì‹  ëŒ€ì—­í­ | - |
| **EFA ë„¤íŠ¸ì›Œí¬** | EFA Monitor | ë…¸ë“œ ê°„ ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬ëŸ‰, íŒ¨í‚· ì†ë„ | - |
| **ì‹œìŠ¤í…œ** | Node Exporter | CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ | 9100 |
| **Slurm** | Custom Collector | ì‘ì—… í, ë…¸ë“œ ìƒíƒœ | - |

### ìë™ ì„¤ì¹˜

ëª¨ë“  ëª¨ë‹ˆí„°ë§ ì»´í¬ë„ŒíŠ¸ëŠ” í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ì„¤ì¹˜ë©ë‹ˆë‹¤:

- **HeadNode**: Prometheus (ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥)
- **ComputeNode (GPU)**: DCGM Exporter + Node Exporter + EFA Monitor
- **ComputeNode (CPU)**: Node Exporterë§Œ ì„¤ì¹˜

### ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ

- [DCGM GPU ëª¨ë‹ˆí„°ë§](guide/DCGM-TO-CLOUDWATCH.md) - GPU ë©”íŠ¸ë¦­ ìƒì„¸
- [NVLink ëª¨ë‹ˆí„°ë§](guide/NVLINK-MONITORING.md) - GPU ê°„ í†µì‹ 
- [EFA ë„¤íŠ¸ì›Œí¬ ëª¨ë‹ˆí„°ë§](guide/EFA-MONITORING.md) - ë…¸ë“œ ê°„ ë„¤íŠ¸ì›Œí¬
- [Prometheus ë©”íŠ¸ë¦­](guide/PROMETHEUS-METRICS.md) - ë©”íŠ¸ë¦­ ì¿¼ë¦¬ ê°€ì´ë“œ
- [AMP + AMG ì„¤ì •](guide/AMP-AMG-SETUP.md) - AWS ê´€ë¦¬í˜• ëª¨ë‹ˆí„°ë§

### ëŒ€ì‹œë³´ë“œ ì ‘ê·¼

```bash
# CloudWatch ëŒ€ì‹œë³´ë“œ (ìë™ ìƒì„±)
# - ParallelCluster-<cluster-name>: ê¸°ë³¸ ëŒ€ì‹œë³´ë“œ
# - ParallelCluster-<cluster-name>-Advanced: ê³ ê¸‰ ë©”íŠ¸ë¦­
# - ParallelCluster-<cluster-name>-EFA: EFA ë„¤íŠ¸ì›Œí¬

# Grafana (self-hosting ë˜ëŠ” AMG)
# - GPU Performance
# - NVLink Bandwidth
# - EFA Network
# - Slurm Jobs
```

## âš ï¸ ê³ ë ¤ì‚¬í•­

### Capacity Blockê³¼ Placement Group

> **ì¤‘ìš”**: Capacity Blockê³¼ Placement Groupì€ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**Capacity Block ì‚¬ìš© ì‹œ**:
- `cluster-config.yaml`ì—ì„œ `PlacementGroup.Enabled: false` ì„¤ì • í•„ìˆ˜
- Single Spine êµ¬ì„±ì´ í•„ìš”í•œ ê²½ìš° Capacity Block ì˜ˆì•½ ì „ AWS Account Teamì— ë¬¸ì˜
- í† í´ë¡œì§€ í™•ì¸: [EC2 Instance Topology](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-topology.html)

**On-Demand/Spot ì‚¬ìš© ì‹œ**:
- Placement Group í™œì„±í™” ê¶Œì¥ (ìµœì ì˜ ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥)

### ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ì„ íƒ

**HeadNodeì™€ LoginNodeëŠ” GPUê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤** - ë¹„ìš© ìµœì í™”ë¥¼ ìœ„í•´ CPU ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

| ë…¸ë“œ íƒ€ì… | ê¶Œì¥ ì¸ìŠ¤í„´ìŠ¤ | ìš©ë„ | ë¹„ìš© ì ˆê° |
|-----------|---------------|------|-----------|
| HeadNode | m5.2xlarge ~ m5.8xlarge | Slurm ìŠ¤ì¼€ì¤„ëŸ¬ | ~99% |
| LoginNode | m5.large ~ m5.2xlarge | ì‚¬ìš©ì ì ‘ê·¼, ì „ì²˜ë¦¬ | ~99% |
| ComputeNode | p5en.48xlarge, p6-b200.48xlarge | GPU ì›Œí¬ë¡œë“œ | - |
| Monitoring | t3.medium | ëª¨ë‹ˆí„°ë§ ì „ìš© | - |

ğŸ“– **ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… ìƒì„¸ ê°€ì´ë“œ**: [guide/INSTANCE-TYPE-CONFIGURATION.md](guide/INSTANCE-TYPE-CONFIGURATION.md)

### ìŠ¤í† ë¦¬ì§€ êµ¬ì„±

#### ê³ ì„±ëŠ¥ ê³µìœ  ìŠ¤í† ë¦¬ì§€
- **FSx Lustre** (`/fsx`): ë°ì´í„°ì…‹, ëª¨ë¸, ì²´í¬í¬ì¸íŠ¸
  - ë©€í‹° GB/s ì²˜ë¦¬ëŸ‰
  - ë³‘ë ¬ I/O ìµœì í™”
  - S3 ì—°ë™ ê°€ëŠ¥

#### Home ë””ë ‰í† ë¦¬ ê³µìœ 

**ì˜µì…˜ 1: HeadNode NFS** (`/home`) - ê¶Œì¥
- ì‚¬ìš©ì íŒŒì¼, ìŠ¤í¬ë¦½íŠ¸, í™˜ê²½ ì„¤ì •
- ì¶”ê°€ ë¹„ìš© ì—†ìŒ
- ì„¤ì • ê°„ë‹¨
- **ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì¶©ë¶„í•œ ì„±ëŠ¥**

**ì˜µì…˜ 2: FSx OpenZFS** (`/home`) - íŠ¹ìˆ˜í•œ ê²½ìš°
- ê³ ì„±ëŠ¥ Home ë””ë ‰í† ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°
- ë§ì€ ì‚¬ìš©ì ë™ì‹œ ì ‘ì† ì‹œ
- ì¶”ê°€ ë¹„ìš© ë°œìƒ
- ì„¤ì • ë³µì¡

> ğŸ’¡ **ê¶Œì¥ì‚¬í•­**: íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­ì´ ì—†ë‹¤ë©´ HeadNode NFSë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤. FSx OpenZFSëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì—ë§Œ ê³ ë ¤í•˜ì„¸ìš”:
> - ìˆ˜ì‹­ ëª… ì´ìƒì˜ ì‚¬ìš©ìê°€ ë™ì‹œì— Home ë””ë ‰í† ë¦¬ì— ì§‘ì¤‘ì ìœ¼ë¡œ I/O ìˆ˜í–‰
> - Home ë””ë ‰í† ë¦¬ì—ì„œ ë†’ì€ IOPSê°€ í•„ìš”í•œ ì‘ì—… ìˆ˜í–‰
> - ìŠ¤ëƒ…ìƒ·, ë³µì œ ë“± ê³ ê¸‰ íŒŒì¼ì‹œìŠ¤í…œ ê¸°ëŠ¥ í•„ìš”

#### ë¡œì»¬ ìŠ¤í† ë¦¬ì§€
- **EBS**: ë£¨íŠ¸ ë³¼ë¥¨ ë° ë¡œì»¬ ìŠ¤í¬ë˜ì¹˜
  - ComputeNode: 200GB+ ê¶Œì¥ (ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ìš©)
  - HeadNode: 500GB+ ê¶Œì¥ (ë¡œê·¸, íŒ¨í‚¤ì§€ìš©)

### WaitCondition íƒ€ì„ì•„ì›ƒ ê´€ë¦¬

ParallelClusterëŠ” ë…¸ë“œ ë°°í¬ ì‹œ CloudFormation WaitConditionì„ ì‚¬ìš©í•˜ë©°, ê¸°ë³¸ íƒ€ì„ì•„ì›ƒì€ 30ë¶„ì…ë‹ˆë‹¤.

**ê¶Œì¥ ì „ëµ**:
1. âœ… **í´ëŸ¬ìŠ¤í„° ìƒì„± ì‹œ**: ìµœì†Œ ì„¤ì¹˜ë§Œ ìˆ˜í–‰ (ë¹ ë¥¸ ë°°í¬)
   - CustomActionsëŠ” ê²½ëŸ‰ ì‘ì—…ë§Œ (Docker, Pyxis, ëª¨ë‹ˆí„°ë§)
   - NCCL ê°™ì€ ëŒ€ìš©ëŸ‰ ì„¤ì¹˜ëŠ” ì œì™¸

2. âœ… **ìƒì„± ì™„ë£Œ í›„**: í•„ìš”í•œ ì†Œí”„íŠ¸ì›¨ì–´ ìˆ˜ë™ ì„¤ì¹˜
   - NCCLì„ FSxì— ì„¤ì¹˜í•˜ì—¬ ê³µìœ 
   - ë˜ëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì‚¬ìš©

3. âœ… **ê³µìœ  ìŠ¤í† ë¦¬ì§€ í™œìš©**: í•œ ë²ˆ ì„¤ì¹˜í•˜ì—¬ ëª¨ë“  ë…¸ë“œì—ì„œ ì°¸ì¡°
   - `/fsx/nccl/` - NCCL ë¼ì´ë¸ŒëŸ¬ë¦¬
   - `/fsx/containers/` - ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€
   - `/fsx/software/` - ê¸°íƒ€ ì†Œí”„íŠ¸ì›¨ì–´

4. âœ… **ì»¨í…Œì´ë„ˆ ì‚¬ìš©**: ì‚¬ì „ êµ¬ì„±ëœ ì´ë¯¸ì§€ í™œìš©
   - NVIDIA NGC ì»¨í…Œì´ë„ˆ (PyTorch, TensorFlow ë“±)
   - ì¬í˜„ì„± ë³´ì¥
   - ì„¤ì¹˜ ì‹œê°„ ì œë¡œ

**ë‹¤ìˆ˜ì˜ ComputeNode ê´€ë¦¬**:
- âœ… **FSx ê³µìœ  ìŠ¤í† ë¦¬ì§€ í™œìš©**: NCCL ë“±ì„ `/fsx`ì— í•œ ë²ˆë§Œ ì„¤ì¹˜í•˜ì—¬ ëª¨ë“  ë…¸ë“œì—ì„œ ì°¸ì¡°
- âœ… **Slurm job ì¼ê´„ ì ìš©**: ê°œë³„ SSH ì ‘ì† ëŒ€ì‹  `srun --nodes=ALL` ì‚¬ìš©
- âœ… **ì»¨í…Œì´ë„ˆ ì‚¬ìš©**: Docker/Singularityë¡œ ì‚¬ì „ êµ¬ì„±ëœ í™˜ê²½ ë°°í¬

ğŸ“– **íƒ€ì„ì•„ì›ƒ ìƒì„¸ ê°€ì´ë“œ**: [guide/TIMEOUT-CONFIGURATION.md](guide/TIMEOUT-CONFIGURATION.md)

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥

### GPU ì¸ìŠ¤í„´ìŠ¤ ì‚¬ì–‘ ì˜ˆì‹œ

**p5en.48xlarge** (H100 ê¸°ë°˜):
| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| vCPUs | 192 |
| Memory | 2,048 GiB (2TB DDR5) |
| GPUs | 8x NVIDIA H100 (80GB HBM3 each) |
| Network | 3,200 Gbps (EFA) |
| NVLink | 900 GB/s per direction |
| Storage | 8x 3.84TB NVMe SSD |

**p6-b200.48xlarge** (B200 ê¸°ë°˜):
| í•­ëª© | ì‚¬ì–‘ |
|------|------|
| vCPUs | 192 |
| Memory | 2,048 GiB (2TB DDR5) |
| GPUs | 8x NVIDIA B200 (192GB HBM3e each) |
| Network | 3,200 Gbps (EFA) |
| NVLink | 900 GB/s per direction |
| Storage | 8x 3.84TB NVMe SSD |

### NCCL ì„±ëŠ¥ ì§€í‘œ

**ë‹¨ì¼ ë…¸ë“œ (NVLink)**:
- AllReduce: 800-1200 GB/s (1GB ë©”ì‹œì§€)
- AllToAll: 200-400 GB/s (128MB ë©”ì‹œì§€)
- ë ˆì´í„´ì‹œ: <100Î¼s (ì†Œí˜• ë©”ì‹œì§€)

**ë©€í‹° ë…¸ë“œ (EFA)**:
- AllReduce: >90% í™•ì¥ íš¨ìœ¨ì„±
- ë„¤íŠ¸ì›Œí¬ í™œìš©: >80% of 3.2Tbps
- ë ˆì´í„´ì‹œ ì¦ê°€: <20Î¼s vs ë‹¨ì¼ ë…¸ë“œ

ğŸ“– **NCCL ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: [guide/NCCL-PERFORMANCE-TESTING.md](guide/NCCL-PERFORMANCE-TESTING.md)

## ğŸ›¡ï¸ Security

### ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] SSH ì ‘ê·¼ì„ íŠ¹ì • IPë¡œ ì œí•œ (`AllowedIPsForLoginNodeSSH`)
- [ ] Monitoring InstanceëŠ” ALBë¥¼ í†µí•´ì„œë§Œ ì ‘ê·¼
- [ ] Grafana ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ë³€ê²½
- [ ] SSM Session Manager ì‚¬ìš© (SSH ëŒ€ì‹ )
- [ ] HeadNode/ComputeNodeëŠ” Private Subnetì— ë°°ì¹˜

### ì•ˆì „í•œ ì ‘ê·¼ ë°©ë²•

```bash
# SSM Session Manager (ê¶Œì¥)
aws ssm start-session --target <Instance-ID>

# Grafana í¬íŠ¸ í¬ì›Œë”©
aws ssm start-session \
  --target <Monitoring-Instance-ID> \
  --document-name AWS-StartPortForwardingSession \
  --parameters '{"portNumber":["3000"],"localPortNumber":["3000"]}'
```

ğŸ“– **ë³´ì•ˆ ê°€ì´ë“œ**: [security-best-practices/SECURITY.md](security-best-practices/SECURITY.md)

## ğŸ” Troubleshooting

**ë¹ ë¥¸ ë¬¸ì œ í•´ê²°**:

```bash
# í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
pcluster describe-cluster --cluster-name my-cluster

# ë¡œê·¸ í™•ì¸
pcluster get-cluster-log-events --cluster-name my-cluster

# ì„¤ì • ê²€ì¦
pcluster validate-cluster-configuration --cluster-configuration cluster-config.yaml
```

## ğŸ“ Additional Guides

- [ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ](guide/QUICKSTART-EFA-MONITORING.md) - EFA ëª¨ë‹ˆí„°ë§ í¬í•¨ ë¹ ë¥¸ ì„¤ì •
- [í´ëŸ¬ìŠ¤í„° ì¬ìƒì„± ê°€ì´ë“œ](guide/CLUSTER-RECREATION-GUIDE.md) - í´ëŸ¬ìŠ¤í„° ì‚­ì œ ë° ì¬ìƒì„± ì ˆì°¨
- [CloudWatch ëª¨ë‹ˆí„°ë§ ì™„ë£Œ](guide/CLOUDWATCH-MONITORING-COMPLETE.md) - CloudWatch í†µí•© ì„¤ì •
- [ì„ íƒì  ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸](guide/OPTIONAL-COMPONENTS-UPDATE.md) - ì¶”ê°€ ê¸°ëŠ¥ ì„¤ì¹˜
- [ë³€ê²½ ì´ë ¥](guide/CHANGELOG-EFA-MONITORING.md) - EFA ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸ ë‚´ì—­

## ğŸ“š Additional Resources

- [AWS ParallelCluster User Guide](https://docs.aws.amazon.com/parallelcluster/)
- [NVIDIA B200 Documentation](https://www.nvidia.com/en-us/data-center/b200/)
- [NCCL Developer Guide](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/)
- [EFA User Guide](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html)

## ğŸ“„ License

This project is licensed under the MIT-0 License.

## ğŸ·ï¸ Tags

`aws` `parallelcluster` `p6` `b200` `gpu` `hpc` `machine-learning` `nccl` `slurm` `efa`
