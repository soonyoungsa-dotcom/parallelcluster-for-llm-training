# Prometheus ìˆ˜ì§‘ ë©”íŠ¸ë¦­ ê°€ì´ë“œ

ParallelCluster HeadNodeì˜ Prometheusê°€ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“  ë©”íŠ¸ë¦­ì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘ êµ¬ì¡°

```
ComputeNode (GPU ëª¨ë“œ)
â”œâ”€â”€ DCGM Exporter (port 9400)
â”‚   â””â”€â”€ GPU ë©”íŠ¸ë¦­ â†’ Prometheus
â””â”€â”€ Node Exporter (port 9100)
    â””â”€â”€ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ â†’ Prometheus

HeadNode
â””â”€â”€ Prometheus (port 9090)
    â”œâ”€â”€ ë¡œì»¬ ì €ì¥ (self-hosting)
    â””â”€â”€ AMP remote_write (amp-only, amp+amg)
```

## ğŸ® DCGM Exporter ë©”íŠ¸ë¦­ (GPU)

**Job Name**: `dcgm`  
**Port**: 9400  
**ìˆ˜ì§‘ ì£¼ê¸°**: 15ì´ˆ

### GPU ì‚¬ìš©ë¥ 
```promql
# GPU ì‚¬ìš©ë¥  (0-100%)
DCGM_FI_DEV_GPU_UTIL{gpu="0", instance_id="i-xxxxx"}

# ì˜ˆì œ ì¿¼ë¦¬: í‰ê·  GPU ì‚¬ìš©ë¥ 
avg(DCGM_FI_DEV_GPU_UTIL)

# ì˜ˆì œ ì¿¼ë¦¬: GPUë³„ ì‚¬ìš©ë¥ 
DCGM_FI_DEV_GPU_UTIL{gpu="0"}
```

### GPU ë©”ëª¨ë¦¬
```promql
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (0-100%)
DCGM_FI_DEV_MEM_COPY_UTIL{gpu="0"}

# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
DCGM_FI_DEV_FB_USED{gpu="0"}

# GPU ë©”ëª¨ë¦¬ ì—¬ìœ  ê³µê°„ (MB)
DCGM_FI_DEV_FB_FREE{gpu="0"}

# ì˜ˆì œ ì¿¼ë¦¬: ì´ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
sum(DCGM_FI_DEV_FB_USED)
```

### GPU ì˜¨ë„
```promql
# GPU ì˜¨ë„ (Â°C)
DCGM_FI_DEV_GPU_TEMP{gpu="0"}

# ì˜ˆì œ ì¿¼ë¦¬: ìµœê³  ì˜¨ë„
max(DCGM_FI_DEV_GPU_TEMP)

# ì˜ˆì œ ì¿¼ë¦¬: ì˜¨ë„ ê²½ê³  (85Â°C ì´ìƒ)
DCGM_FI_DEV_GPU_TEMP > 85
```

### GPU ì „ë ¥
```promql
# GPU ì „ë ¥ ì†Œë¹„ (W)
DCGM_FI_DEV_POWER_USAGE{gpu="0"}

# ì˜ˆì œ ì¿¼ë¦¬: ì´ ì „ë ¥ ì†Œë¹„
sum(DCGM_FI_DEV_POWER_USAGE)

# ì˜ˆì œ ì¿¼ë¦¬: í‰ê·  ì „ë ¥ ì†Œë¹„ (5ë¶„)
avg_over_time(DCGM_FI_DEV_POWER_USAGE[5m])
```

### GPU í´ëŸ­
```promql
# SM (Streaming Multiprocessor) í´ëŸ­ (MHz)
DCGM_FI_DEV_SM_CLOCK{gpu="0"}

# ë©”ëª¨ë¦¬ í´ëŸ­ (MHz)
DCGM_FI_DEV_MEM_CLOCK{gpu="0"}
```

### GPU ì—ëŸ¬
```promql
# ECC ì—ëŸ¬ (Single-bit)
DCGM_FI_DEV_ECC_SBE_VOL_TOTAL{gpu="0"}

# ECC ì—ëŸ¬ (Double-bit)
DCGM_FI_DEV_ECC_DBE_VOL_TOTAL{gpu="0"}

# XID ì—ëŸ¬
DCGM_FI_DEV_XID_ERRORS{gpu="0"}
```

### GPU PCIe
```promql
# PCIe ì†¡ì‹  ì²˜ë¦¬ëŸ‰ (KB/s)
DCGM_FI_DEV_PCIE_TX_THROUGHPUT{gpu="0"}

# PCIe ìˆ˜ì‹  ì²˜ë¦¬ëŸ‰ (KB/s)
DCGM_FI_DEV_PCIE_RX_THROUGHPUT{gpu="0"}

# PCIe ì¬ìƒ íšŸìˆ˜
DCGM_FI_DEV_PCIE_REPLAY_COUNTER{gpu="0"}
```

### NVLINK (H100)
```promql
# NVLINK ëŒ€ì—­í­ ì‚¬ìš©ë¥ 
DCGM_FI_DEV_NVLINK_BANDWIDTH_TOTAL{gpu="0"}

# NVLINK ì—ëŸ¬
DCGM_FI_PROF_NVLINK_RX_BYTES{gpu="0"}
DCGM_FI_PROF_NVLINK_TX_BYTES{gpu="0"}
```

## ğŸ–¥ï¸ Node Exporter ë©”íŠ¸ë¦­ (ì‹œìŠ¤í…œ)

**Job Name**: `compute-nodes`  
**Port**: 9100  
**ìˆ˜ì§‘ ì£¼ê¸°**: 15ì´ˆ

### CPU
```promql
# CPU ì‚¬ìš© ì‹œê°„ (ì´ˆ)
node_cpu_seconds_total{mode="idle", instance_id="i-xxxxx"}
node_cpu_seconds_total{mode="user"}
node_cpu_seconds_total{mode="system"}
node_cpu_seconds_total{mode="iowait"}

# ì˜ˆì œ ì¿¼ë¦¬: CPU ì‚¬ìš©ë¥  (%)
100 - (avg by (instance_id) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# ì˜ˆì œ ì¿¼ë¦¬: CPU ì½”ì–´ë³„ ì‚¬ìš©ë¥ 
rate(node_cpu_seconds_total{mode!="idle"}[5m])
```

### ë©”ëª¨ë¦¬
```promql
# ì´ ë©”ëª¨ë¦¬ (bytes)
node_memory_MemTotal_bytes

# ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (bytes)
node_memory_MemAvailable_bytes

# ì‚¬ìš© ì¤‘ì¸ ë©”ëª¨ë¦¬ (bytes)
node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes

# ì˜ˆì œ ì¿¼ë¦¬: ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# ë²„í¼/ìºì‹œ
node_memory_Buffers_bytes
node_memory_Cached_bytes

# Swap
node_memory_SwapTotal_bytes
node_memory_SwapFree_bytes
```

### ë””ìŠ¤í¬
```promql
# ë””ìŠ¤í¬ ì‚¬ìš© ê³µê°„ (bytes)
node_filesystem_size_bytes{mountpoint="/"}
node_filesystem_avail_bytes{mountpoint="/"}
node_filesystem_used_bytes{mountpoint="/"}

# ì˜ˆì œ ì¿¼ë¦¬: ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (%)
(node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_avail_bytes{mountpoint="/"}) / node_filesystem_size_bytes{mountpoint="/"} * 100

# FSx Lustre
node_filesystem_size_bytes{mountpoint="/fsx"}
node_filesystem_avail_bytes{mountpoint="/fsx"}
```

### ë””ìŠ¤í¬ I/O
```promql
# ì½ê¸° ë°”ì´íŠ¸ (bytes)
rate(node_disk_read_bytes_total[5m])

# ì“°ê¸° ë°”ì´íŠ¸ (bytes)
rate(node_disk_written_bytes_total[5m])

# I/O ì‹œê°„ (ì´ˆ)
rate(node_disk_io_time_seconds_total[5m])

# ì˜ˆì œ ì¿¼ë¦¬: ë””ìŠ¤í¬ ì²˜ë¦¬ëŸ‰ (MB/s)
rate(node_disk_read_bytes_total[5m]) / 1024 / 1024
rate(node_disk_written_bytes_total[5m]) / 1024 / 1024
```

### ë„¤íŠ¸ì›Œí¬
```promql
# ìˆ˜ì‹  ë°”ì´íŠ¸ (bytes)
rate(node_network_receive_bytes_total{device="eth0"}[5m])

# ì†¡ì‹  ë°”ì´íŠ¸ (bytes)
rate(node_network_transmit_bytes_total{device="eth0"}[5m])

# ì˜ˆì œ ì¿¼ë¦¬: ë„¤íŠ¸ì›Œí¬ ì²˜ë¦¬ëŸ‰ (Mbps)
rate(node_network_receive_bytes_total{device="eth0"}[5m]) * 8 / 1000000
rate(node_network_transmit_bytes_total{device="eth0"}[5m]) * 8 / 1000000

# ì—ëŸ¬ ë° ë“œë¡­
node_network_receive_errs_total
node_network_transmit_errs_total
node_network_receive_drop_total
node_network_transmit_drop_total
```

### ì‹œìŠ¤í…œ ë¶€í•˜
```promql
# Load Average
node_load1   # 1ë¶„ í‰ê· 
node_load5   # 5ë¶„ í‰ê· 
node_load15  # 15ë¶„ í‰ê· 

# ì˜ˆì œ ì¿¼ë¦¬: CPU ì½”ì–´ë‹¹ ë¶€í•˜
node_load5 / count(node_cpu_seconds_total{mode="idle"})
```

### í”„ë¡œì„¸ìŠ¤
```promql
# ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ìˆ˜
node_procs_running

# ì°¨ë‹¨ëœ í”„ë¡œì„¸ìŠ¤ ìˆ˜
node_procs_blocked

# ì´ í”„ë¡œì„¸ìŠ¤ ìˆ˜
node_processes_state{state="running"}
node_processes_state{state="sleeping"}
node_processes_state{state="zombie"}
```

### ì‹œìŠ¤í…œ ì •ë³´
```promql
# ë¶€íŒ… ì‹œê°„ (Unix timestamp)
node_boot_time_seconds

# ì˜ˆì œ ì¿¼ë¦¬: ì—…íƒ€ì„ (ì‹œê°„)
(time() - node_boot_time_seconds) / 3600

# ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹˜
rate(node_context_switches_total[5m])

# ì¸í„°ëŸ½íŠ¸
rate(node_intr_total[5m])
```

## ğŸ“ˆ ìœ ìš©í•œ PromQL ì¿¼ë¦¬ ì˜ˆì œ

### GPU ëª¨ë‹ˆí„°ë§

#### 1. ì „ì²´ GPU ì‚¬ìš©ë¥ 
```promql
# í‰ê·  GPU ì‚¬ìš©ë¥ 
avg(DCGM_FI_DEV_GPU_UTIL)

# ë…¸ë“œë³„ í‰ê·  GPU ì‚¬ìš©ë¥ 
avg by (instance_id) (DCGM_FI_DEV_GPU_UTIL)

# GPUë³„ ì‚¬ìš©ë¥ 
DCGM_FI_DEV_GPU_UTIL
```

#### 2. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
```promql
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)
(DCGM_FI_DEV_FB_USED / (DCGM_FI_DEV_FB_USED + DCGM_FI_DEV_FB_FREE)) * 100

# ë…¸ë“œë³„ ì´ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
sum by (instance_id) (DCGM_FI_DEV_FB_USED)
```

#### 3. GPU ì˜¨ë„ ê²½ê³ 
```promql
# 85Â°C ì´ìƒì¸ GPU
DCGM_FI_DEV_GPU_TEMP > 85

# ìµœê³  ì˜¨ë„
max(DCGM_FI_DEV_GPU_TEMP)
```

#### 4. GPU ì „ë ¥ ì†Œë¹„
```promql
# ì´ ì „ë ¥ ì†Œë¹„ (W)
sum(DCGM_FI_DEV_POWER_USAGE)

# ë…¸ë“œë³„ ì „ë ¥ ì†Œë¹„
sum by (instance_id) (DCGM_FI_DEV_POWER_USAGE)

# 5ë¶„ í‰ê·  ì „ë ¥ ì†Œë¹„
avg_over_time(sum(DCGM_FI_DEV_POWER_USAGE)[5m:])
```

### ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

#### 1. CPU ì‚¬ìš©ë¥ 
```promql
# ì „ì²´ CPU ì‚¬ìš©ë¥  (%)
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# ë…¸ë“œë³„ CPU ì‚¬ìš©ë¥ 
100 - (avg by (instance_id) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

#### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
```promql
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# ì‚¬ìš© ì¤‘ì¸ ë©”ëª¨ë¦¬ (GB)
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / 1024 / 1024 / 1024
```

#### 3. ë””ìŠ¤í¬ I/O
```promql
# ì½ê¸° ì²˜ë¦¬ëŸ‰ (MB/s)
rate(node_disk_read_bytes_total[5m]) / 1024 / 1024

# ì“°ê¸° ì²˜ë¦¬ëŸ‰ (MB/s)
rate(node_disk_written_bytes_total[5m]) / 1024 / 1024

# ì´ I/O ì²˜ë¦¬ëŸ‰
(rate(node_disk_read_bytes_total[5m]) + rate(node_disk_written_bytes_total[5m])) / 1024 / 1024
```

#### 4. ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­
```promql
# ìˆ˜ì‹  ëŒ€ì—­í­ (Mbps)
rate(node_network_receive_bytes_total{device="eth0"}[5m]) * 8 / 1000000

# ì†¡ì‹  ëŒ€ì—­í­ (Mbps)
rate(node_network_transmit_bytes_total{device="eth0"}[5m]) * 8 / 1000000

# EFA ë„¤íŠ¸ì›Œí¬ (p5 ì¸ìŠ¤í„´ìŠ¤)
rate(node_network_receive_bytes_total{device=~"efa.*"}[5m]) * 8 / 1000000
```

### ë¶„ì‚° í•™ìŠµ ëª¨ë‹ˆí„°ë§

#### 1. ë©€í‹° ë…¸ë“œ GPU ì‚¬ìš©ë¥ 
```promql
# ëª¨ë“  ë…¸ë“œì˜ í‰ê·  GPU ì‚¬ìš©ë¥ 
avg(DCGM_FI_DEV_GPU_UTIL)

# ë…¸ë“œë³„ GPU ì‚¬ìš©ë¥  (8 GPU per node)
avg by (instance_id) (DCGM_FI_DEV_GPU_UTIL)

# GPU ì‚¬ìš©ë¥  ë¶„ì‚° (í‘œì¤€í¸ì°¨)
stddev(DCGM_FI_DEV_GPU_UTIL)
```

#### 2. ë„¤íŠ¸ì›Œí¬ í†µì‹  (All-Reduce)
```promql
# ë…¸ë“œ ê°„ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½
sum(rate(node_network_transmit_bytes_total[5m]))

# NVLINK ëŒ€ì—­í­ (ë…¸ë“œ ë‚´ GPU í†µì‹ )
sum(DCGM_FI_DEV_NVLINK_BANDWIDTH_TOTAL)
```

#### 3. í•™ìŠµ ë³‘ëª© ê°ì§€
```promql
# GPU ì‚¬ìš©ë¥ ì´ ë‚®ì€ ë…¸ë“œ (< 50%)
DCGM_FI_DEV_GPU_UTIL < 50

# CPU I/O waitì´ ë†’ì€ ë…¸ë“œ (> 20%)
rate(node_cpu_seconds_total{mode="iowait"}[5m]) * 100 > 20

# ë©”ëª¨ë¦¬ ë¶€ì¡± ë…¸ë“œ (> 90%)
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
```

## ğŸ¯ Grafana ëŒ€ì‹œë³´ë“œ ì˜ˆì œ

### GPU ëŒ€ì‹œë³´ë“œ íŒ¨ë„

#### Panel 1: GPU ì‚¬ìš©ë¥ 
```promql
# Query
avg(DCGM_FI_DEV_GPU_UTIL)

# Visualization: Gauge
# Thresholds: 
#   - Green: 0-70
#   - Yellow: 70-90
#   - Red: 90-100
```

#### Panel 2: GPU ë©”ëª¨ë¦¬
```promql
# Query
sum(DCGM_FI_DEV_FB_USED) / 1024  # GB

# Visualization: Time series
# Unit: GB
```

#### Panel 3: GPU ì˜¨ë„
```promql
# Query
max(DCGM_FI_DEV_GPU_TEMP)

# Visualization: Stat
# Thresholds:
#   - Green: 0-75
#   - Yellow: 75-85
#   - Red: 85-100
```

#### Panel 4: GPU ì „ë ¥
```promql
# Query
sum(DCGM_FI_DEV_POWER_USAGE)

# Visualization: Time series
# Unit: Watt
```

### ì‹œìŠ¤í…œ ëŒ€ì‹œë³´ë“œ íŒ¨ë„

#### Panel 1: CPU ì‚¬ìš©ë¥ 
```promql
# Query
100 - (avg by (instance_id) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Visualization: Time series
# Legend: {{instance_id}}
```

#### Panel 2: ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
```promql
# Query
(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100

# Visualization: Gauge
```

#### Panel 3: ë„¤íŠ¸ì›Œí¬ I/O
```promql
# Query A (Receive)
rate(node_network_receive_bytes_total{device="eth0"}[5m]) * 8 / 1000000

# Query B (Transmit)
rate(node_network_transmit_bytes_total{device="eth0"}[5m]) * 8 / 1000000

# Visualization: Time series
# Unit: Mbps
```

## ğŸ“š ë©”íŠ¸ë¦­ ë³´ì¡´ ê¸°ê°„

### Self-hosting
- **ë¡œì»¬ ì €ì¥**: 15ì¼ (ê¸°ë³¸ê°’)
- **ì„¤ì • ìœ„ì¹˜**: `/opt/prometheus/prometheus.yml`
- **ë³€ê²½ ë°©ë²•**: `--storage.tsdb.retention.time=30d`

### AMP (amp-only, amp+amg)
- **ë¡œì»¬ ì €ì¥**: 1ì‹œê°„ (ì„ì‹œ)
- **AMP ì €ì¥**: 150ì¼ (ìë™)
- **ë¹„ìš©**: ì €ì¥ ìš©ëŸ‰ì— ë”°ë¼ ê³¼ê¸ˆ

## ğŸ” ë©”íŠ¸ë¦­ í™•ì¸ ë°©ë²•

### Prometheus UI
```bash
# HeadNodeì—ì„œ
curl http://localhost:9090/api/v1/targets

# ë¸Œë¼ìš°ì €ì—ì„œ (í¬íŠ¸ í¬ì›Œë”© í•„ìš”)
ssh -L 9090:localhost:9090 headnode
# http://localhost:9090
```

### PromQL ì¿¼ë¦¬
```bash
# ë©”íŠ¸ë¦­ ëª©ë¡ í™•ì¸
curl http://localhost:9090/api/v1/label/__name__/values

# íŠ¹ì • ë©”íŠ¸ë¦­ ì¿¼ë¦¬
curl 'http://localhost:9090/api/v1/query?query=DCGM_FI_DEV_GPU_UTIL'
```

### Grafana Explore
1. Grafana â†’ Explore
2. Data source: Amazon Managed Prometheus
3. Metric browserì—ì„œ ë©”íŠ¸ë¦­ ì„ íƒ
4. Run query

## ğŸ“Š ìš”ì•½

### GPU ë©”íŠ¸ë¦­ (DCGM)
- âœ… ì‚¬ìš©ë¥ , ë©”ëª¨ë¦¬, ì˜¨ë„, ì „ë ¥
- âœ… í´ëŸ­, PCIe, NVLINK
- âœ… ECC ì—ëŸ¬, XID ì—ëŸ¬
- **ì´**: ~50ê°œ ë©”íŠ¸ë¦­

### ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ (Node Exporter)
- âœ… CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ë„¤íŠ¸ì›Œí¬
- âœ… ë¶€í•˜, í”„ë¡œì„¸ìŠ¤, I/O
- **ì´**: ~200ê°œ ë©”íŠ¸ë¦­

### ìˆ˜ì§‘ ì£¼ê¸°
- **Scrape interval**: 15ì´ˆ
- **Evaluation interval**: 15ì´ˆ
- **Remote write**: 30ì´ˆ (AMP)

### ì €ì¥ ìš©ëŸ‰ ì˜ˆìƒ
- **ë…¸ë“œë‹¹**: ~1-2 MB/hour
- **10 ë…¸ë“œ**: ~10-20 MB/hour
- **ì›”ê°„**: ~7-15 GB/month
